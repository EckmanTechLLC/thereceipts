# Phase 4.1b: Adversarial Re-Verification

**Date:** 2026-01-18
**Type:** Implementation
**Status:** Complete

---

## Context

Phase 4.1a complete (Core API Integration + Verified Source Library).
Phase 4.1b integrates SourceVerificationService into Adversarial Checker agent to re-verify quotes against actual API sources.

**Problem Addressed:**
- Adversarial Checker previously had no way to verify quotes against actual source content
- Could only evaluate plausibility, not accuracy
- No verification of URLs, context, or page numbers

**References:**
- ADR 004: Multi-Source Verification
- Phase 4.1a session notes (source verification core implementation)

---

## Implementation Summary

### Modified File: `src/backend/agents/adversarial_checker.py`

**Changes:**

1. **Added imports** (lines 12-19):
   - `os` for environment variables
   - `List` from typing
   - `SourceVerificationService`, `SourceVerificationResult` from services.source_verification
   - `VerifiedSourceRepository` from database.repositories

2. **Initialize verification service in `__init__`** (lines 37-45):
   - Creates `VerifiedSourceRepository` from db_session
   - Initializes `SourceVerificationService` with API keys:
     - `OPENAI_API_KEY` (for embeddings and LLM relevance checks)
     - `GOOGLE_BOOKS_API_KEY` (Tier 1)
     - `TAVILY_API_KEY` (Tier 4)
     - `SEMANTIC_SCHOLAR_API_KEY` (Tier 2, optional)

3. **Added `_reverify_sources()` method** (lines 154-267):
   - Takes claim_text, primary_sources, scholarly_sources
   - For each source:
     - Re-verifies using multi-tier system (same as Source Checker)
     - Compares quote_text against actual source content from APIs
     - Checks URL validity via `url_verified` flag
     - Flags discrepancies (quote mismatch, broken URLs, verification failures)
   - Returns formatted verification notes string

4. **Integrated into `execute()` method** (lines 75-80):
   - Calls `_reverify_sources()` before constructing LLM prompt
   - Includes reverification results in user message for LLM context
   - Adds `reverification_notes` to return dict (line 140)

---

## Verification Logic

### Quote Comparison

**Approach:**
- If API returns `content_snippet` (Google Books description, Semantic Scholar abstract, etc.):
  - Check if quote_text exists in content_snippet (case-insensitive)
  - If not exact match: Calculate word overlap ratio (first 10 words)
  - Flag if overlap < 50%

**Limitations:**
- APIs provide limited content (snippets, abstracts, not full text)
- Cannot verify exact page numbers (APIs don't provide page-level access)
- Cannot check full context (would require complete source text)

**Trade-off:**
- Basic verification better than none
- Catches major discrepancies (completely wrong source, hallucinated quotes)
- Transparent about limitations (flags low confidence matches)

### URL Verification

**Approach:**
- Compares original URL from Source Checker with re-verified URL
- Checks `url_verified` flag from verification service (HEAD request test)
- Flags if URLs don't match or URL is broken

### Verification Tiers

Uses same 5-tier system as Source Checker:
- **Tier 0:** Verified source library (semantic search + LLM relevance)
- **Tier 1:** Google Books API
- **Tier 2:** Semantic Scholar API
- **Tier 4:** Tavily API (web sources)
- **Tier 5:** LLM fallback (unverified)

**Note:** Tier 3 (Ancient Texts) deferred to Phase 4.1c.

### Discrepancy Flagging

**Flags raised for:**
- ⚠ Failed re-verification (all API tiers failed)
- ⚠ URL mismatch (original vs verified URL different)
- ⚠ URL broken or inaccessible
- ⚠ Quote may not match source content (low word overlap)
- ⚠ Re-verification error (exception during verification)

**Success indicators:**
- ✓ Verified via [method] (tier [0-2])

**No pipeline failure:**
- Discrepancies flagged in `reverification_notes`
- Pipeline continues (transparency over failure per ADR 004)
- LLM sees flags and can adjust confidence/verdict accordingly

---

## Integration Flow

### End-to-End Flow (with Phase 4.1b)

1. **User asks question** → Router Agent → Pipeline (if novel claim)

2. **Topic Finder Agent** runs → identifies claim

3. **Source Checker Agent** runs (Phase 4.1a):
   - Identifies source queries
   - Verifies each via multi-tier system
   - Returns sources with verification metadata

4. **Adversarial Checker Agent** runs (Phase 4.1b):
   - Receives claim + sources from previous agents
   - **NEW:** Calls `_reverify_sources()`:
     - For each source: Re-verify using verification service
     - Compare quote_text against API content
     - Check URL validity
     - Flag discrepancies
   - Includes reverification notes in LLM prompt
   - LLM evaluates claim with awareness of source verification status
   - Returns verdict + confidence + verification_notes + **reverification_notes**

5. **Writer Agent** runs → generates explanation text

6. **Publisher Agent** runs → stores claim card in database

---

## Design Decisions

### 1. Re-Verification vs Trusting Source Checker

**Why re-verify in Adversarial Checker?**
- Adversarial role requires independent verification
- Source Checker may have false positives (library hits that aren't truly relevant)
- URLs may have changed or broken between agents
- LLM may have hallucinated quotes even with verified sources

**Trade-off:**
- +5-10s per claim card (additional API calls)
- Higher confidence in final verdict
- Catches discrepancies before publication

### 2. Basic Quote Comparison (Word Overlap)

**Why not exact matching?**
- APIs provide limited content (snippets/abstracts, not full text)
- Exact quote may not appear in snippet even if source is correct
- Word overlap catches major discrepancies while allowing paraphrasing

**Why 50% threshold?**
- < 50% suggests completely different content
- >= 50% suggests same topic, possibly paraphrased
- Balance between false positives (flagging valid quotes) and false negatives (missing bad quotes)

**Alternative considered:**
- Semantic similarity via embeddings
- Rejected: Too expensive (additional embedding calls per source)
- Current approach sufficient for Phase 4.1b

### 3. Including Reverification Notes in LLM Prompt

**Why tell the LLM about verification results?**
- LLM can adjust confidence based on verification status
- LLM can note specific concerns in `verification_notes`
- Transparency: LLM's verdict informed by actual source verification

**Alternative considered:**
- Store reverification notes separately, don't tell LLM
- Rejected: LLM should know about source quality when evaluating claim

### 4. No Pipeline Failure on Verification Failure

**Rationale:**
- ADR 004 principle: Transparency over failure
- Better to have claim card with flagged sources than no card
- Admin/user can evaluate credibility themselves
- Some sources may be correct despite verification API failures

---

## Files Modified

**Modified:**
- `src/backend/agents/adversarial_checker.py` (+125 lines: imports, initialization, _reverify_sources method, integration)

**Total:** ~125 lines of implementation

---

## Testing Notes

### Prerequisites

1. Ensure API keys in `.env` (from Phase 4.1a):
   - `GOOGLE_BOOKS_API_KEY`
   - `TAVILY_API_KEY`
   - `SEMANTIC_SCHOLAR_API_KEY`
   - `OPENAI_API_KEY`

2. Ensure Phase 4.1a migration applied:
   ```bash
   alembic current  # Should show: d6638e843688
   ```

3. Backend running with dependencies installed:
   ```bash
   cd src/backend
   source venv/bin/activate
   pip install -r requirements.txt
   uvicorn main:app --host 0.0.0.0 --port 8008
   ```

### Manual Testing

**Test 1: Full Pipeline with Re-Verification**
1. Ask novel question requiring new claim card
2. Watch for Adversarial Checker step in WebSocket events
3. Check agent_audit in database:
   - Should contain `reverification_notes` field
   - Should show verification results (✓ or ⚠ flags)

**Test 2: Verification Discrepancies**
1. Use claim with sources that can't be re-verified (obscure books, broken URLs)
2. Check reverification_notes in agent_audit:
   - Should flag: "Failed re-verification" or "URL appears broken"
3. Check that pipeline completes (doesn't fail)
4. Check LLM's verdict: Should reflect uncertainty about source quality

**Test 3: Library Hits (Tier 0)**
1. Run pipeline for similar claims (e.g., "Gospel authorship" twice)
2. First run: Sources verified via Tier 1-2, added to library
3. Second run: Re-verification should hit library (Tier 0)
4. Check reverification_notes: Should show "Verified via library_reuse_..." with tier 0

**Test 4: Quote Comparison**
1. Run pipeline for claim with well-known book (e.g., Bart Ehrman)
2. Check if Google Books returns description/snippet
3. Reverification_notes should show:
   - ✓ if quote found in snippet
   - ⚠ if quote not found in snippet (low word overlap)

**Edge Cases:**
- Sources with no quote_text (should skip re-verification)
- Sources with no citation (should skip re-verification)
- All API tiers fail (should flag: "Failed re-verification (all API tiers failed, tier 5)")
- Verification service raises exception (should flag: "Re-verification error: [exception]")

---

## Success Criteria

Phase 4.1b complete when:
- [x] SourceVerificationService imported into Adversarial Checker
- [x] Verification service initialized with API keys
- [x] `_reverify_sources()` method implemented:
  - [x] Re-verifies each source via multi-tier system
  - [x] Compares quote_text against API content (word overlap)
  - [x] Checks URL validity
  - [x] Flags discrepancies
- [x] Integrated into `execute()`:
  - [x] Calls before LLM prompt construction
  - [x] Includes reverification notes in LLM context
  - [x] Returns reverification_notes in output
- [x] No pipeline failure on verification failures (transparency over failure)

**Testing:** User will run services and test end-to-end pipeline.

---

## Performance Impact

**Current Pipeline (Phase 4.1a):** ~55-70s per claim card
- Source Checker: +5-10s (API verification of 4-8 sources)

**With Phase 4.1b (Adversarial Re-Verification):**
- Adversarial Checker: +5-10s (re-verification of same 4-8 sources)
- Library hits reduce time (Tier 0 faster than Tier 1-4)

**Estimated Total:** ~60-80s per claim card (acceptable per ADR 004)

**Optimization:**
- Library hits from Source Checker enable faster re-verification in Adversarial Checker
- Over time, library grows → more Tier 0 hits → faster verification

---

## Next Steps (Phase 4.1c)

**Ancient Texts Integration:**

Add Tier 3 API integration for ancient/religious texts:
- CCEL (Christian Classics Ethereal Library)
- Perseus Digital Library (ancient Greek/Latin texts)
- Early Church Texts

**Files to modify:**
- `src/backend/services/source_verification.py` (add Tier 3 methods)

**Implementation:**
1. Research CCEL, Perseus, Early Church Texts APIs
2. Add Tier 3 methods to SourceVerificationService
3. Update verify_source() to attempt Tier 3 between Tier 2 and Tier 4
4. Test with Christianity-focused claims requiring ancient texts

---

## Notes

**Design Principles Maintained:**
- Fail soft (no pipeline failures on verification failures)
- Full transparency (reverification notes visible in agent_audit)
- Database-stored prompts (LLM calls use agent prompt from database)
- No shortcuts (all sources re-verified, not just sampled)

**User Preferences Honored:**
- Concise implementation (~125 lines, single file)
- Small incremental change (Phase 4.1b scope only)
- Stayed within defined task
- Documented as we went

**Limitations Acknowledged:**
- APIs provide limited content (snippets, not full text)
- Cannot verify exact page numbers (APIs lack page-level access)
- Cannot check full context (would require complete source text)
- Quote comparison is basic (word overlap, not semantic similarity)

**Future Enhancements (Not Phase 4.1):**
- Semantic similarity for quote comparison (embeddings)
- Manual verification workflow (admin flags sources for physical book check)
- Automatic re-verification of existing claim cards (mass update)
- Page number verification (requires OCR or enhanced APIs)

---

**Status:** Implementation complete, ready for testing and Phase 4.1c (Ancient Texts Integration).
