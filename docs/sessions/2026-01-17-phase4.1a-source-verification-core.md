# Phase 4.1a: Core API Integration + Verified Source Library

**Date:** 2026-01-17
**Type:** Implementation
**Status:** Complete

---

## Context

Phase 3 complete (Auto-Blog system).
Phase 4.1a implements multi-tier source verification to address critical issues with source quality identified in Phase 1-3.

**Problems Addressed:**
- URLs are LLM-generated (often broken or point to wrong sources)
- Citations from training data (may be incorrect or outdated)
- Quotes paraphrased from memory (not from actual source text)
- Page numbers unverified (often inaccurate)
- No way to verify claims against actual source content

**References:**
- ADR 004: Multi-Source Verification
- Phase 3.3 session notes (scheduler/autosuggest patterns)

---

## Implementation Summary

### 1. Database Migration

**File:** `src/backend/database/migrations/versions/d6638e843688_add_verified_sources_table_and_source_.py`

**Changes:**

Created `verified_sources` table (Tier 0 library):
- `id` (UUID, primary key)
- `source_type` (string: book, paper, ancient_text)
- `title` (string, 1000 chars)
- `author` (string, 500 chars)
- `publisher` (string, nullable)
- `publication_date` (string, nullable)
- `isbn` (string, nullable)
- `doi` (string, nullable)
- `url` (text, verified working URL)
- `content_snippet` (text, sample content)
- `topic_keywords` (array of strings)
- `embedding` (vector 1536, for semantic search)
- `verification_method` (string: google_books, semantic_scholar, etc.)
- `verification_status` (string: verified, partially_verified)
- `created_at`, `updated_at` (timestamps)

Indexes: source_type, title, author

Added verification columns to `sources` table:
- `verification_method` (string, nullable)
- `verification_status` (string, nullable)
- `content_type` (string, nullable: exact_quote, verified_paraphrase, unverified_content)
- `url_verified` (boolean, default false)

Indexes: verification_method, verification_status

**Purpose:**
- `verified_sources`: Library of reusable source metadata (Tier 0)
- `sources`: Per-claim source entries with verification metadata

---

### 2. VerifiedSource Model

**File:** `src/backend/database/models.py`

Added `VerifiedSource` model after `Source` model (lines 165-208).

**Key Features:**
- Stores book/paper metadata with embeddings
- Enables semantic search for library hits (Tier 0)
- Metadata reusable, quotes claim-specific
- Separate from per-claim `sources` table

Updated `Source` model with verification columns (lines 146-150).

---

### 3. VerifiedSourceRepository

**File:** `src/backend/database/repositories.py`

Added `VerifiedSourceRepository` at end of file (lines 682-787).

**Key Methods:**

**`search_by_similarity(embedding, threshold=0.85, limit=5)`**
- Semantic search in library using pgvector cosine similarity
- Returns list of (VerifiedSource, similarity_score) tuples
- Threshold 0.85 per ADR 004

**`find_by_title_author(title, author)`**
- Exact match lookup for duplicate prevention

**`create(verified_source)`, `update()`, `delete()`, `count()`**
- Standard CRUD operations

---

### 4. API Client Dependencies

**File:** `src/backend/requirements.txt`

Added:
```
# API Clients (Phase 4.1: Source Verification)
google-api-python-client==2.115.0
tavily-python==0.7.19
```

**Notes:**
- Semantic Scholar uses public API via httpx (already present)
- httpx already installed for Anthropic/OpenAI SDKs

---

### 5. SourceVerificationService

**File:** `src/backend/services/source_verification.py` (580 lines)

**Purpose:** Multi-tier source verification with 5 tiers (Tier 0-2, 4-5).

#### SourceVerificationResult Class

Data class for verification results:
- `success` (bool)
- `tier` (int: 0-5)
- `verification_method` (string)
- `verification_status` (string: verified, partially_verified, unverified)
- `citation` (string)
- `url` (string)
- `quote_text` (string, nullable)
- `content_type` (string: exact_quote, verified_paraphrase, unverified_content)
- `url_verified` (bool)
- `metadata` (dict)

#### SourceVerificationService Class

**Initialization:**
- Takes `VerifiedSourceRepository` for library access
- Loads API keys from environment:
  - `GOOGLE_BOOKS_API_KEY`
  - `TAVILY_API_KEY`
  - `SEMANTIC_SCHOLAR_API_KEY` (optional)
- Initializes OpenAI client for embeddings and LLM relevance checks
- Initializes Tavily client

**Main Method: `verify_source(claim_text, source_query, source_type)`**

Attempts each tier in order:
1. **Tier 0:** Check library (semantic search + LLM relevance check)
2. **Tier 1:** Google Books API
3. **Tier 2:** Semantic Scholar API
4. **Tier 4:** Tavily API
5. **Tier 5:** LLM fallback (unverified)

Returns first successful SourceVerificationResult.

#### Tier Implementations

**Tier 0: `_check_library(claim_text, source_query)`**
- Generates embedding for claim + source query
- Semantic search in library (threshold 0.85)
- LLM relevance check for top 3 candidates
- Returns verified metadata if relevant source found
- Reuses book metadata, quote must be claim-specific

**LLM Relevance Check: `_llm_relevance_check()`**
- Uses GPT-4o-mini to evaluate if library source addresses claim
- Returns YES/NO for relevance
- Prevents forced matches from semantic search alone

**Tier 1: `_check_google_books(source_query)`**
- Calls Google Books API with search query
- Extracts metadata: title, authors, publisher, date, ISBN
- Gets preview/info link and description
- Verifies URL exists
- Returns SourceVerificationResult with verified metadata
- Adds to library via `_add_to_library()`

**Tier 2: `_check_semantic_scholar(source_query)`**
- Calls Semantic Scholar public API
- Extracts paper metadata: title, authors, year, abstract, DOI
- Gets paper URL
- Verifies URL exists
- Returns SourceVerificationResult with verified metadata
- Adds to library via `_add_to_library()`

**Tier 4: `_check_tavily(source_query)`**
- Calls Tavily API for web search
- Extracts title, URL, content snippet
- Verifies URL exists
- Returns SourceVerificationResult (partially_verified)
- Does NOT add to library (web sources not reusable)

**Tier 5: `_llm_fallback()`**
- Returns unverified placeholder
- Source Checker will generate from LLM training data
- Marked as `llm_unverified` with unverified status

#### Helper Methods

**`_verify_url(url)`**
- Tests URL with HEAD request (5s timeout)
- Returns True if status 200, False otherwise

**`_add_to_library(result)`**
- Adds Tier 1-2 verified sources to library
- Generates embedding for title + author keywords
- Creates VerifiedSource entry
- Enables future reuse (Tier 0)

---

### 6. Source Checker Agent Integration

**File:** `src/backend/agents/source_checker.py`

**Changes:**

**Imports:**
- Added `SourceVerificationService`, `SourceVerificationResult`
- Added `VerifiedSourceRepository`

**Initialization:**
- Creates `VerifiedSourceRepository` from db_session
- Creates `SourceVerificationService` with repo

**New Workflow in `execute()`:**

1. **Step 1:** Identify source queries via `_identify_source_queries()`
   - LLM generates list of search queries for sources
   - Returns primary_source_queries and scholarly_source_queries
   - Each query has: search_query, usage_context

2. **Step 2:** Verify each source via `verification_service.verify_source()`
   - Calls multi-tier verification for each query
   - Collects SourceVerificationResults

3. **Step 3:** Format results via `_format_source_result()`
   - Converts SourceVerificationResult to pipeline dict
   - Includes verification metadata: method, status, content_type, url_verified

4. **Step 4:** Generate evidence summary via `_generate_evidence_summary()`
   - LLM summarizes what sources show about claim
   - Uses verified citations and quotes

**New Methods:**

**`_identify_source_queries(claim, claimant, claim_type)`**
- Asks LLM: What sources are needed to evaluate this claim?
- Returns JSON with search queries and usage context
- Guidelines: specific queries (e.g., "Bart Ehrman Misquoting Jesus")

**`_format_source_result(result, query)`**
- Formats SourceVerificationResult for pipeline output
- Includes original fields: citation, quote, url, usage_context
- Adds Phase 4.1 fields: verification_method, verification_status, content_type, url_verified

**`_generate_evidence_summary(claim, primary_sources, scholarly_sources)`**
- Generates 2-3 sentence summary of what evidence shows
- Uses LLM with verified source citations and quotes

---

## Design Decisions

### 1. Tier 0 (Library) Semantic Search + LLM Relevance Check

**Why two-step approach:**
- Semantic search alone can match irrelevant books (similar keywords)
- LLM relevance check prevents forced matches
- Example: "Gospel of John" semantic match could return any Gospel commentary
- LLM checks: "Does this specific book address this specific claim?"

**Trade-off:**
- +2-3s per library search (LLM call)
- Higher accuracy (no false library hits)

### 2. Library Reuses Metadata, Not Quotes

**Rationale:**
- Book metadata is reusable (title, author, URL verified once)
- Quotes are claim-specific (different pages for different claims)
- Source Checker generates fresh quotes per claim

**Implementation:**
- Library hit returns verified URL + metadata
- `quote_text` remains None in library result
- Source Checker extracts quote from verified source

### 3. Only Tier 1-2 Added to Library

**Tier 1-2 (books, papers):**
- Stable, reusable metadata
- Added to library after verification

**Tier 4 (web sources):**
- Transient, not reusable
- Not added to library

**Tier 5 (LLM fallback):**
- Unverified, not trustworthy
- Not added to library

### 4. Source Checker Two-Step Workflow

**Step 1: Identify queries**
- LLM generates search queries for needed sources
- Separates "what to look for" from "how to find it"

**Step 2: Verify via APIs**
- Multi-tier system attempts verification
- Falls back gracefully to LLM if all tiers fail

**Alternative considered:**
- Single LLM call generates citations directly
- Rejected: No opportunity for API verification

### 5. Fail-Soft Behavior (Tier 5)

**If all API tiers fail:**
- Allow source with `llm_unverified` status
- Mark as unverified in database
- Display disclaimer in UI (Phase 4.1d)

**Rationale:**
- Better to have claim card with some sources than no card
- Transparency about limitations aligns with project principles
- Admin can manually verify later if needed

**Important:** System genuinely attempts all tiers before falling back.

---

## Integration Flow (End-to-End)

### Source Verification Flow

1. **User asks question** → Router Agent → Pipeline (if novel claim)

2. **Topic Finder Agent** runs → identifies claim

3. **Source Checker Agent** runs:
   - Step 1: Ask LLM: "What sources are needed?"
   - LLM returns: [{"search_query": "Bart Ehrman Misquoting Jesus", "usage_context": "..."}]

4. **For each source query:**
   - Call `verification_service.verify_source()`

5. **Verification service tries Tier 0:**
   - Generate embedding for "claim + query"
   - Semantic search library (threshold 0.85)
   - If candidates found: LLM relevance check
   - If relevant: Return library source (verified metadata)
   - If not relevant: Skip to Tier 1

6. **If Tier 0 misses, try Tier 1 (Google Books):**
   - Search Google Books API
   - Extract metadata (title, author, ISBN, URL)
   - Verify URL exists
   - Return SourceVerificationResult
   - Add to library for future reuse

7. **If Tier 1 fails, try Tier 2 (Semantic Scholar):**
   - Search Semantic Scholar API
   - Extract paper metadata (title, authors, DOI, abstract)
   - Verify URL exists
   - Return SourceVerificationResult
   - Add to library for future reuse

8. **If Tier 2 fails, try Tier 4 (Tavily):**
   - Search Tavily web API
   - Extract title, URL, content snippet
   - Verify URL exists
   - Return SourceVerificationResult (partially_verified)

9. **If Tier 4 fails, Tier 5 (LLM fallback):**
   - Return unverified placeholder
   - Source Checker will generate from LLM training data
   - Mark as `llm_unverified`

10. **Source Checker** collects all verified sources

11. **Generate evidence summary** via LLM

12. **Pipeline continues** to Adversarial Checker → Writer → Publisher

---

## Files Created/Modified

**Created:**
- `src/backend/database/migrations/versions/d6638e843688_add_verified_sources_table_and_source_.py` (79 lines)
- `src/backend/services/source_verification.py` (580 lines)
- `docs/sessions/2026-01-17-phase4.1a-source-verification-core.md` (this file)

**Modified:**
- `src/backend/database/models.py` (+48 lines: VerifiedSource model, Source verification columns)
- `src/backend/database/repositories.py` (+107 lines: VerifiedSourceRepository, imports)
- `src/backend/requirements.txt` (+4 lines: google-api-python-client, tavily-python)
- `src/backend/agents/source_checker.py` (+111 lines: verification integration, new workflow)
- `src/backend/config.py` (+6 lines: API key settings)

**Total:** ~936 lines of implementation

---

## Environment Setup (COMPLETE)

Added to `.env` file:
```
GOOGLE_BOOKS_API_KEY=AIzaSyCfvbSKhgYtjiVpKO_lW_KQ-JioPX-_0Yk
TAVILY_API_KEY=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
SEMANTIC_SCHOLAR_API_KEY=LHAISg2amG9TGZo5vRDqq9CtJbeH7AHo8SkPAiop
```

Dependencies installed:
```bash
pip install google-api-python-client==2.115.0
pip install tavily-python==0.7.19
```

Migration run:
```bash
alembic upgrade head
# INFO: Running upgrade c29cd8c921ce -> d6638e843688
```

**Note:** tavily-python 0.3.0 had tiktoken build issues (no Rust compiler). Updated to 0.7.19 which uses prebuilt tiktoken wheels.

---

## Testing Notes

### Manual Testing (After Implementation)

**Prerequisites:**
1. Ensure API keys added to `.env`
2. Run migration: `alembic upgrade head`
3. Install dependencies: `pip install -r requirements.txt`
4. Start backend: `uvicorn main:app --host 0.0.0.0 --port 8008`

**Test Source Verification Service:**

1. **Test Tier 1 (Google Books):**
   - Search: "Bart Ehrman Misquoting Jesus"
   - Expected: Book metadata returned, URL verified
   - Check: `verified_sources` table populated

2. **Test Tier 2 (Semantic Scholar):**
   - Search: "Wallace manuscript textual criticism"
   - Expected: Paper metadata returned, DOI extracted
   - Check: `verified_sources` table populated

3. **Test Tier 0 (Library):**
   - Repeat search from Test 1
   - Expected: Library hit (no API call), similarity >0.85
   - Expected: LLM relevance check passes

4. **Test Tier 4 (Tavily):**
   - Search: "Ancient manuscript discovery 2020"
   - Expected: Web source returned, partially_verified

5. **Test Tier 5 (LLM fallback):**
   - Disable API keys temporarily
   - Expected: Returns llm_unverified result

**Test Source Checker Agent Integration:**

1. **Run pipeline** with novel claim: "Did Jesus claim to be God?"
   - Check: Source Checker identifies 4-8 source queries
   - Check: Each query verified via multi-tier system
   - Check: Sources have verification metadata in response

2. **Check database:**
   - `sources` table: verification_method, verification_status, content_type populated
   - `verified_sources` table: New entries for verified books/papers

3. **Run pipeline again** with similar claim
   - Check: Library hits (Tier 0) for previously verified sources
   - Check: Faster execution (library hits skip API calls)

**Edge Cases:**

- Empty source queries (LLM fails to generate queries)
  - Expected: Empty sources arrays, evidence summary = "Unable to generate"

- All API tiers fail
  - Expected: Tier 5 fallback, llm_unverified status

- URL verification fails
  - Expected: url_verified=False, source still created

---

## Success Criteria

Phase 4.1a complete when:
- [x] Database migration created (verified_sources table + sources columns)
- [x] VerifiedSource model added to models.py
- [x] VerifiedSourceRepository added to repositories.py
- [x] API client dependencies added to requirements.txt
- [x] SourceVerificationService implements 5-tier system:
  - [x] Tier 0: Library semantic search + LLM relevance check
  - [x] Tier 1: Google Books API
  - [x] Tier 2: Semantic Scholar API
  - [x] Tier 4: Tavily API
  - [x] Tier 5: LLM fallback
- [x] Source Checker Agent integrated with verification service:
  - [x] Two-step workflow (identify queries → verify)
  - [x] Formats results with verification metadata
  - [x] Generates evidence summary
- [x] Session notes documented

**Not Tested Yet:** Manual testing required (user will run services and test).

---

## Next Steps (Phase 4.1b)

**Adversarial Re-Verification:**

Integrate SourceVerificationService into Adversarial Checker agent:

1. For each source in claim card:
   - Re-verify using same API tier system
   - Compare quote_text against actual source content
   - Verify context (surrounding text, not out of context)
   - Verify page numbers match quote location

2. Flag discrepancies:
   - Quote doesn't match source
   - Quote taken out of context
   - Page numbers incorrect
   - URL broken or wrong source

3. Handle verification failures:
   - Mark source as failed re-verification
   - Include Adversarial Checker notes in agent_audit
   - Do NOT fail pipeline (transparency over failure)

**Files to modify:**
- `src/backend/agents/adversarial_checker.py` (integrate verification service)

---

## Notes

**Design Principles Maintained:**
- Fail soft (Tier 5 fallback, transparency over failure)
- Full transparency (verification status visible in metadata)
- Database-stored prompts (used by Source Checker LLM calls)
- No shortcuts (all sources attempted through API tiers)

**User Preferences Honored:**
- Concise session notes (~280 lines)
- Small incremental changes (Phase 4.1a scope only)
- Stayed within defined task
- Documented as we went

**Deviations from ADR 004:**
- Tier 3 (Ancient Texts) deferred to Phase 4.1c as specified
- LLM relevance check added to Tier 0 (not in original ADR, improves accuracy)
- Source Checker two-step workflow (identify queries → verify) improves separation of concerns

**API Rate Limits:**
- Google Books: 1,000 queries/day (free tier, sufficient for current volume)
- Semantic Scholar: 100 requests/5min (free tier, sufficient)
- Tavily: 1,000 queries/month (free tier, sufficient for fallback)

**Performance Impact:**
- Current pipeline: ~45-60s per claim card
- With verification: +5-10s (API calls for 4-8 sources)
- With library hits: +0-2s (semantic search + LLM relevance check)
- **Estimated:** ~55-70s per claim card (acceptable per ADR 004)

---

**Status:** Implementation complete, ready for Phase 4.1b (Adversarial Re-Verification).
